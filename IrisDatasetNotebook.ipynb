{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset\n",
    "![Iris flowers](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produced by the biologist Robert Fisher in the 1930's, the Iris flower dataset is widely recognised as the best known dataset to be found in the pattern recognition literature. <br>The dataset consists of three species of the Iris flower\n",
    " - Iris setosa\n",
    " - Iris virginica\n",
    " - Iris versicolor\n",
    "\n",
    "The Iris data contains 50 samples of each of these three species and it measures their sepal length, sepal width, petal length and petal width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: No module named 'pandas._libs.tslib' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     from pandas._libs import (hashtable as _hashtable,\n\u001b[0m\u001b[0;32m     27\u001b[0m                              \u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtslib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimedelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas._libs.tslib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8d0b03894a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Importing pandas and seaborn for data visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m                       \u001b[1;34m\"pandas from the source directory, you may need to run \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                       \u001b[1;34m\"'python setup.py build_ext --inplace --force' to build \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                       \"the C extensions first.\".format(module))\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: C extension: No module named 'pandas._libs.tslib' not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "#Importing numpy for use with dataset\n",
    "import numpy as np\n",
    "\n",
    "#Importing pandas and seaborn for data visualization\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "#Importing matplotlib for use with graphs\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "import warnings\n",
    "\n",
    "#Importing the iris data set from the iris.csv file\n",
    "dataset = pd.read_csv(\"data/iris.csv\")\n",
    "\n",
    "#Ignoring deprecated warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first going to take a look at the data that is within the iris dataset.<br> Using the head() function we can view the first 20 records in the dataset, which allows us to see how it is present within.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the first 20 records within the data set\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the info() function allows us to gain some insight on the dataset as a whole. Here we can see that there are 150 total records consisting of 6 different columns. We can see there are 4 columns containing floats, 1 containing an object and 1 containing an int. <br>We can also see how much memory is in usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we gain info on the data set\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see that there are clearly 50 records for each of the three species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the pairplot function, to view the data as a series of graphs. This data set becomes alot more meaningful when it is visualized in such a way. We can better understand the relationship between the three different species.<br> Simply looking at data which is in text form without any visual aid can lead the data to be somewhat incomprehensible to the user overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graphs = sb.pairplot(dataset, hue='species', markers='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are making use of a violin plot to visualize the data, which is like a box plot. The difference being that the violin plot will show you the probabilty density of the data at seperate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = sb.violinplot(x='species', y='sepal_length', data=dataset, inner='quartile')\n",
    "plot.show()\n",
    "graph = sb.violinplot(x='species', y='sepal_width', data=dataset, inner='quartile')\n",
    "plot.show()\n",
    "graph = sb.violinplot(x='species', y='petal_length', data=dataset, inner='quartile')\n",
    "plot.show()\n",
    "graph = sb.violinplot(x='species', y='petal_width', data=dataset, inner='quartile') \n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon visualizing this data it appears that the setosa species of the iris flower is the most distinct of the three, with the versicolor and virginica species being more closly related. <br>However the latter species are still clearly distinguishable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours (KNN) classifcation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is used widely in industry for classification problems. It is one of the simplest classification algorithims out there, but it provides us with competitive results nonetheless. Classification is about taking samples of labeled data, and using those samples to predict the class of unlabeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the sub-package neighbors from sklearn package\n",
    "import sklearn.neighbors as nb\n",
    "\n",
    "#Importing pandas as pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the iris data set from the iris.csv file\n",
    "dataset = pd.read_csv(\"data/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign our inputs and outputs so we that we can use that to train our classifier on the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "outputs = dataset['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNeighborsClassifier is a class in python. The function below creates a data structure which represents the KNN algorithim where K is set to 5 in this case. It will select its 5 nearest neighbours. So if we give a point and 4 out of 5 of its nearest neighbors are a versicolor.<br> The algorithm will decide that that species is a versicolor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = nb.KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first train the classifier on the dataset. We give the knn.fit() function the inputs for which we know the outputs, and also those outputs.<br> The function will use these data points to build the model for what the species looks like, so that we can in turn make predictions for future specimens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the loc function we can access a group of values using a label (In this case 10).\n",
    "<br>Here can clearly see the sepal_length, sepal_width, petal_length, petal_width and species of that object.\n",
    "<br>We can use this to prove that the KNN algorithm is working correctly in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing a group of values using labels\n",
    "dataset.loc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see the KNN algorithm has predicted correctly\n",
    "knn.predict([[5.4,3.7,1.5,0.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that the algorithm is working correctly as it has predicted that the above is a setosa. We know that those values are infact of a setosa as we have checked that using the loc function.\n",
    "<br>Lets make a few more predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict([[6,3,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict([[5,2,4,1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict([[6,3,6,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
