{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DigitRecognitionNotebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A jupyter notebook explaining how the Python script works and discussing its performance. \n",
    "<br>This is the supplementary notebook for the Digit Recognition script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports needed for the script to compile.\n",
    "<br>I have commented the use of each import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy as np.\n",
    "import numpy as np\n",
    "#Importing gzip for use with .gz files.\n",
    "import gzip\n",
    "#Import keras for use with neural network.\n",
    "import keras as kr\n",
    "#Importing sklearn.preprocessing for encoding categorical variables.\n",
    "import sklearn.preprocessing as pre\n",
    "#Importing Sequential, Dense and Dropout for building model.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "#Importing Image from python image library for use with images.\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "We begin by creating a function which builds the neural network necessary to identify the handwritten digit.\n",
    "<br>We use a Sequential model which builds the neural network by layers.\n",
    "<br>We follow this by reading in the MNIST data set.\n",
    "<br>This is used to train the model, so that the neural network will be as accurate as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nueralNetwork(userImage):\n",
    "    #Starting a neural network, building it by layers.\n",
    "    model = Sequential()\n",
    "\n",
    "    #https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py#L53\n",
    "    #Creating a sequential model\n",
    "    model.add(Dense(512, activation='relu', input_dim=784))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    #Printing a summary of the model.\n",
    "    model.summary()\n",
    "\n",
    "    #Building the graph.\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    #Using gzip to open the images in the data file to train the model\n",
    "    with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "        train_img = f.read()\n",
    "\n",
    "    #Using gzip to open the labels in the data file to train the model\n",
    "    with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "        train_lbl = f.read()\n",
    "\n",
    "    #Reshape images and labels\n",
    "    train_img = np.array(list(train_img[16:])).reshape(60000, 1, 784).astype(np.uint8) / 255.0\n",
    "    train_lbl = np.array(list(train_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "    #Reshape image array\n",
    "    inputs = train_img.reshape(60000, 784)\n",
    "\n",
    "    #Binarize labels in a one-vs-all fashion\n",
    "    encoder = pre.LabelBinarizer()\n",
    "    #Fit label encoder\n",
    "    encoder.fit(train_lbl)\n",
    "    #Transforming labels to normalized encoding.\n",
    "    outputs = encoder.transform(train_lbl)\n",
    "\n",
    "    #Training the model\n",
    "    model.fit(inputs, outputs, epochs=6, batch_size=128)\n",
    "\n",
    "    #Transforming labels back to original encoding and predicting the user image.\n",
    "    print(\"According to the nueral network the digit is: \")\n",
    "    print(encoder.inverse_transform(model.predict(userImage)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Image\n",
    "This function takes an image and processes it so that it can be used by the neural network.\n",
    "<br>We take a series of steps to achieve this.\n",
    "<br>A youtube series by a man named John Hammond helped to understand how to use PIL (Pythons Imaging Library) which adds image processing capabilities to your Python interpreter.\n",
    "<br>https://www.youtube.com/watch?v=dkrXgzuZk3k&list=PL1H1sBF1VAKXCayO4KZqSmym2Z_sn6Pha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputImage(userImage):\n",
    "    \n",
    "    #https://www.youtube.com/watch?v=3RVnDX8cO4s\n",
    "    #Reading in an image and converting it to greyscale.\n",
    "    image = Image.open(userImage).convert('L')\n",
    "\n",
    "    #Resizing the image into 28x28 pixels so it is compatible.\n",
    "    image = image.resize((28, 28), Image.BICUBIC)\n",
    "\n",
    "    #https://www.youtube.com/watch?v=DdNvYxtXlD8\n",
    "    #Getting the data from the image\n",
    "    image = list(image.getdata())\n",
    "    \n",
    "    #https://www.youtube.com/watch?v=yi_dDsRqvK0\n",
    "    #Normalize the pixels to 0 and 1. 0 is pure white and 1 is pure black\n",
    "    image = [(255 - x) * 1.0 / 255.0 for x in image]\n",
    "\n",
    "    #Reshaping the image for use with neural network.\n",
    "    image = np.array(list(image)).reshape(1, 784)\n",
    "\n",
    "    #Run the neural network\n",
    "    nueralNetwork(image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menu\n",
    "The last last function serves as a very simple menu, which asks the user for a path to an image as input.\n",
    "<br>This image is then passed onto the function that deals with processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu():\n",
    "    #Getting an image from the user.\n",
    "    print(\"Welcome to my nueral network\")\n",
    "    print(\"Enter full path of image including file extension\")\n",
    "    userImage = input(\"\")\n",
    "    inputImage(userImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60000/60000 [==============================] - 11s 182us/step - loss: 0.2321 - acc: 0.9317\n",
    "<br>Epoch 2/6\n",
    "<br>60000/60000 [==============================] - 13s 219us/step - loss: 0.0898 - acc: 0.9722\n",
    "<br>Epoch 3/6\n",
    "<br>60000/60000 [==============================] - 9s 158us/step - loss: 0.0618 - acc: 0.9806\n",
    "<br>Epoch 4/6\n",
    "<br>60000/60000 [==============================] - 9s 155us/step - loss: 0.0466 - acc: 0.9851\n",
    "<br>Epoch 5/6\n",
    "<br>60000/60000 [==============================] - 9s 158us/step - loss: 0.0354 - acc: 0.9887\n",
    "<br>Epoch 6/6\n",
    "<br>60000/60000 [==============================] - 10s 169us/step - loss: 0.0284 - acc: 0.9906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
